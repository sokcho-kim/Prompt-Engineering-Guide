{
  "source": "Part 4. 프롬프트 제작의 기초 - 핵심 원리와 방법론 (Chapter 1).pdf",
  "parsed_at": "2026-01-09T17:57:58.635210",
  "total_pages": 70,
  "pages_with_text": 63,
  "pages_needing_ocr": 7,
  "ocr_page_numbers": [
    5,
    12,
    20,
    42,
    59,
    60,
    68
  ],
  "pages": [
    {
      "page_num": 1,
      "text": "국내 공채1호 프롬프트 엔지니어 강수진의\n프롬프트 엔지니어링 A to Z\nPrompt Engineering",
      "char_count": 59,
      "word_count": 12,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 2,
      "text": "Chapter 3. Part 4\n프롬프트 테스트 환경 구축 및 최적화\nOpen AI Playground 사용법",
      "char_count": 61,
      "word_count": 14,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 3,
      "text": "Chapter 3. Part 04. 프롬프트제작의기초:핵심원리\nOpen AI\nPlayground\n1. Chat\n2. Assistants\n3. Completions",
      "char_count": 90,
      "word_count": 14,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 4,
      "text": "Chapter 3. Part 04. 프롬프트제작의기초:핵심원리\nChat\no Chat Completions API 와 연계\no 최신 챗 모델을 사용할 수 있음 (gpt-4o, gpt-4 등)",
      "char_count": 105,
      "word_count": 22,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 5,
      "text": "Chapter 3. Part 04. 프롬프트 제작의 기초: 핵심 원리 \nAssistants \nPlayground New in Assistants API ↗ 日 Learn more \n① asst_o6VuHod0Sy9A9lYGplYm5S1Y 0 THREAD Logs □ \nName \nEnter a user friendly name \nasst_ o6VuHodOSy9A9IYGplYm5S1Y \nInstructions \nYou are a helpful assistant. \nModel \ngpt-4o \nTOOLS \nFile search ① + Files \nCode interpreter ⓘ + Files \nFunctions ① + Functions \nMODEL CONFIGURATION Enter your message... \nResponce form at + Run 36 ← \nClone Updated 6/9, 4:28 PM \nPlayground messages can be viewed by anyone at your organization using the API. \nFast campus",
      "char_count": 550,
      "word_count": 88,
      "needs_ocr": true,
      "ocr_status": "success"
    },
    {
      "page_num": 6,
      "text": "Chapter 3. Part 04. 프롬프트제작의기초:핵심원리\nAssistants API 의 기본 요소\no Assistants(cid:13205) 모델(cid:13273)GPT(cid:13258)3.5, GPT(cid:13258)4, etc(cid:13274), instruction(cid:13273)지시문/프롬프트(cid:13274),\ntools(cid:13273)도구(cid:13274), files(cid:13273)업로드한 파일(cid:13274)를 캡슐화\no 함수: 외부 API 호출을 추가할 수 있음 어시스턴트는 적절하다고 판단되면 이 함수를\n호출함\no 코드 인터프리터: 어시스턴트가 필요에 따라 코드를 작성하고 실행할 수 있게 함\no 검색 및 파일: 업로드된 파일에서 필요한 정보를 검색할 수 있음\no Threads: 대화 채널. 메시지를 담음\no Runs: Assistant (cid:13961) Thread 실행. Run 단계에서 tools(cid:13273)도구(cid:13274) 의 활용 여부 결정\nRun 을 수행한 후 Assistant 가 응답한 결과 처리",
      "char_count": 549,
      "word_count": 85,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 7,
      "text": "Chapter 3. Part 04. 프롬프트제작의기초:핵심원리\nCompletions\no Open AI 가 처음 제공한 API, 레거시 컴플리션 모드\no babbage-002, davinci-002, gpt-3.5-turbo-instruct\n세 가지 모델만 지원\no 채팅 모드가 아님\no 문장을 입력하면, 모델이 문장을 완성하려고 시도\n(cid:13273)예시(cid:13274)",
      "char_count": 211,
      "word_count": 36,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 8,
      "text": "Chapter 3. Part 04. 프롬프트제작의기초:핵심원리\nOpen AI\nPlayground\n1. Temperature\n2. Top P\n3. Maximum Tokens\n4. Frequency Penalty\n5. Presence Penalty\n6. Stop Sequence",
      "char_count": 153,
      "word_count": 25,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 9,
      "text": "Chapter 3. Part 04. 프롬프트제작의기초:핵심원리\n생성 조건 이해하기\nOpen AI Playground\n온도 (cid:13273)temperature(cid:13274) 빈도 패널티 (cid:13273)frequency(cid:13255)penalty(cid:13274)\n최대 토큰 수 (cid:13273)max(cid:13255)tokens(cid:13274) 존재 패널티 (cid:13273)presence(cid:13255)penalty(cid:13274)\n상위 p (cid:13273)top(cid:13255)p(cid:13274) 중지 시퀀스 (cid:13273)Stop Sequences(cid:13274)",
      "char_count": 352,
      "word_count": 30,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 10,
      "text": "Chapter 3. Part 04. 프롬프트제작의기초:핵심원리\n토큰 (Token)\n자연어처리에서 기본적으로 처리할 수 있는 언어의 (cid:13363)조각(cid:13380)이나 (cid:13363)단위(cid:13364)\n프롬프트를 제작할 때는 토큰 수를 미리 예상 할 수 있어야함\n토크 나이저 (Tokenizer) • 토크나이저를 사용하면 텍스트를 언어 모델이 처리할 수 있는 형식으로 변환함.\n• 단어, 구두점 또는 단어의 일부를 개별 토큰으로 분할함.\n영어 예시",
      "char_count": 262,
      "word_count": 50,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 11,
      "text": "Chapter 3. Part 04. 프롬프트제작의기초:핵심원리\n토큰 (Token)\n• 한국어와 같은 다른 언어를 처리할 때는 추가적인 토크나이징 과정을 거침\n• 영어에서는 공백을 기준으로 단어를 구분하지만,\n한국어에서는 음절, 형태소, 단어 등 다양한 기준으로 토큰화 할 수 있음\n한국어 예시",
      "char_count": 163,
      "word_count": 37,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 12,
      "text": "Chapter 3. Part 04. 프롬프트 제작의 기초: 핵심 원리 \nPredict the next token \nInput text Tokenize LLM Output Sample \nprobabilities \nWe 0.001 \nights 0.001 \n[1135, 2337, 1222, \nWeights & Biases is \n8436, 1386, 318, & 0.001 machine \nthe \n262] \nthe 0.001 \nmachine 0.15 \nlearning 0.001 \nplatform 0.2 \nFast campus",
      "char_count": 293,
      "word_count": 49,
      "needs_ocr": true,
      "ocr_status": "success"
    },
    {
      "page_num": 13,
      "text": "Chapter 3. Part 04. 프롬프트제작의기초:핵심원리\n온도 (cid:13273)Temperature(cid:13274)\n높은 온도:\n예시: 한국의 여름 거리를 묘사해줘.\n모델에서 출력의 다양성을 조절하기 위해 사용함\n값이 높을수록 모델이 더 많은 선택지를 가지고 있으며\n결과적으로 더 다양한 텍스트를 생성함\n낮은 온도일수록 모델이 더 확신 있게 예측을 한다\n일반적으로 더 정확하고 일관된 텍스트를 생성함\n낮은 온도:\n예시: 한국의 여름 거리를 묘사해줘.",
      "char_count": 258,
      "word_count": 54,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 14,
      "text": "Chapter 3. Part 04. 프롬프트제작의기초:핵심원리\n상위 Top P\n모델이 다음 단어를 선택할 때 확률이 상위 P(cid:13984)에 해당하는\n단어들만 고려하도록 하는 것\n확률 분포의 상위 P(cid:13984)에 속하는 단어들만 후보로 선택하여\n더 다양한 텍스트를 생성할 수 있음\nTemperature를 매우 높게 했을 때\n결과가 무너지는 것을 방지하기 위해 추가로 사용 가능\nSource: Holtzman, A., Buys, J., Du, L., Forbes, M., & Choi, Y. (2019). The curious case of neural text degeneration.arXivpreprint arXiv:1904.09751.",
      "char_count": 366,
      "word_count": 69,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 15,
      "text": "Chapter 3. Part 04. 프롬프트제작의기초:핵심원리\no 확률 분포가 넓은 경우 o 확률 분포가 좁은 경우",
      "char_count": 64,
      "word_count": 15,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 16,
      "text": "Chapter 3. Part 04. 프롬프트제작의기초:핵심원리\nFrequency Penalty\n모델이 이전에 선택한 토큰이나 패턴과 비슷한 토큰을\n다시 선택하는 것을 억제하는 옵션.\n반복되는 패턴을 피하고 다양성을 유지하는 데 도움이 됨.\n(cid:13273)예시(cid:13274)\n이전 단어가 (cid:13379)사과(cid:13379)였을 때 모델이 다시\n(cid:13379)사과(cid:13379)를 선택하지 않도록 하여 단어의 반복을 줄임.",
      "char_count": 251,
      "word_count": 41,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 17,
      "text": "Chapter 3. Part 04. 프롬프트제작의기초:핵심원리\nPresence Penalty\nPresence penalty는 특정 토큰 또는\n패턴의 등장을 억제하는 데 사용\n모델이 특정 토큰이나 패턴을 생성하지 않도록 하여\n출력의 다양성을 높이고 원하는 결과를 얻을 수 있음\n원하지 않는 단어나 특정 패턴의 등장을 줄이는데 유용",
      "char_count": 183,
      "word_count": 40,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 18,
      "text": "Chapter 03. Part 04\nPrompt Engineering Techniques\nLevel : Basic (cid:13249) Advanced (cid:13247) Applications",
      "char_count": 109,
      "word_count": 14,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 19,
      "text": "Chapter 3\nTaxonomy of Prompt Engineering Techniques\nAdvanced\nBasic Applications\n• Generate Knowledge Prompting, •데이터생성과분류하기\n•Zero-Shot Prompting Prompt Chaining, Tree of Thoughts\n•코드생성하기\n•Few-Shot Prompting • Retrieval Augmented Generation,\n•펑션콜함수\nAutomatic Prompt Engineer,\n•Chain-of-Thought Prompting\nActive-Prompt, Directional Stimulus\n•Self-consistency Prompting, React",
      "char_count": 373,
      "word_count": 41,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 20,
      "text": "Chapter 3 \nPrompt Engineering Techniques \nBasic \nFast campus",
      "char_count": 60,
      "word_count": 8,
      "needs_ocr": true,
      "ocr_status": "success"
    },
    {
      "page_num": 21,
      "text": "Course Objectives & Learning Outcomes\n학습 목표\nü01\n프롬프트 엔지니어링 기초 기법을 이해한다.\n02\n연구 논문을 통해 각 프롬프트 엔지니어링 기법의 핵심과 한계를 이해한다.\n03\n실습을 통해 각 프롬프트 엔지니어링 방법을 학습한다.",
      "char_count": 148,
      "word_count": 32,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 22,
      "text": "Table of Contents\n01 Zero-Shot Prompting\n02 Few-Shot Prompting\n03 Chain-of-Thought Prompting\n04 Self-Consistency",
      "char_count": 112,
      "word_count": 14,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 23,
      "text": "Chapter 3\nThe Basic Prompt Engineering Techniques\n01. Zero(cid:13247)Shot Prompting\no Instruction-Tuning\no RLHF (Reinforcement Learning form Human Feedback)",
      "char_count": 156,
      "word_count": 19,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 24,
      "text": "Chapter 03. Part04.엔지니어링기법-Basic\nResearch Paper\nOpen AI : Language Models are Few-shot Learners (2020)\nFigure 2.1: Zero-shot, one-shot and few-shot, contrasted with\ntraditional fine-tuning. The panels above show four methods for\nperforming a task with a language model – fine-tuning is the\ntraditional method, whereas zero-, one-, and few-shot, which we\nstudy in this work, require the model to perform the task with only\nforward passes at test time. We typically present the model with a\nfew dozen examples in the few shot setting.\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners.Advances in neural information processing\nsystems,33, 1877-1901.",
      "char_count": 734,
      "word_count": 113,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 25,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nZero-Shot Prompting\no 언어 모델에게 예제나 시연(cid:13273)Demonstrations(cid:13274) 을 주지 않고 작업을 수행하는 방법\no 언어 모델이 기존 지식을 사용하여 작업을 추론함\no 대량의 데이터를 사전 학습 했기 때문에 가능\n제로샷 프롬프트는 언어 모델의 강력한 기능 중 하나\n최소한의 정보만으로도 다양한 작업을 수행할 수 있음\n이 기술은 특히 데이터가 부족한 상황에서 유용하게 활용됨",
      "char_count": 273,
      "word_count": 57,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 26,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nExample\no Text Classification o Translation o Closed Question Answering\nPrompt: Prompt: Prompt:\n다음 텍스트에서 긍정, 부정, 중립 중 다음 한국어 단어를 영어로 번역해줘. 대한민국의 수도는 서울이야?\n하나로 분류해.\n단어: 인공 눈물\n텍스트(cid:13205) 나는 마라탕 맛이 그저 그랬어.\nSentiment:",
      "char_count": 252,
      "word_count": 44,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 27,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\no 제로샷 프롬프팅의 작동 방식\no 텍스트와 분류 예시를 모델에게 제공하지 않았는데도 정답을 맞춤",
      "char_count": 89,
      "word_count": 19,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 28,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nResearch Paper\nFINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS (2022)\no 연구 개요: 대형 언어 모델의 제로 샷 학습 능력을 개선법 연구\n자연어 지시로 60개 이상의 NLP 데이터셋에 대해 137B 파라미터 모델을 미세 조정\no 연구 결과 : 모델 FLAN은 제로샷 성능에서 기본 모델보다 우수함\nInstruction Tuning 은 사전 학습 데이터 없이도 NLP 데이터셋에서 모델의 성능을 올림\nInstruction Tuning\no 기술 개요\no 기술의 장점\no 언어 모델의 제로 샷 능력을 향상 시키기 위한 기술 o Instruction tuning 은 모델 크기가 충분할 때 효과적\no Instruction Tuning은 대형 언어 모델이 다양한 작업을 수행할 수 있도록 함\no 지시에 따라 모델의 응답을 미세 조정할 수 있음\no 다수의 작업 클러스터에서 Instruction tuning 시 (cid:13278)모델이 해보지 않은\no 챗봇이 더 정확하고 좋은 결과물을 얻어냄\n작업에 대한 성능 향상\n* 137B 는(cid:13361)B(cid:13362)는billion을의미한다.\nWei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B., ... & Le, Q. V. (2021). Finetuned language models are zero-shot learners.arXivpreprint arXiv:2109.01652.",
      "char_count": 790,
      "word_count": 160,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 29,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\n다양한 NLP 작업에서 우수한 성능을 보여주는 그래프\no FLAN 137B는 Zero(cid:13247)shot prompting 성능에서 다른 대형\n언어 모델들보다 전반적으로 더 우수한 성능을 보임.\no 자연어 추론\nFLAN 137B는 대부분의 작업에서 다른 모델보다 성능 좋음\no 독해\n여러 모델이 유사한 성능을 보이지만, FLAN 137B는 여전히 우수한 성능을 보임\no 폐쇄형 QA\nFLAN 137B와 다른 모델들이 유사한 성능을 보이는 작업도\n있지만, FLAN 137B가 더 좋은 성능을 보이는 작업도 있음\no 번역\nFLAN 137B는 몇 가지 번역 작업에서 다른 모델들보다 성능이 뛰어남\n• X축 (cid:13273)가로축(cid:13274): 제로샷 성능, 값이 클수록 성능이 좋음\n• Y축 (cid:13273)세로축(cid:13274): 테스트된 작업의 유형\n• 작업 유형: 자연어 추론, 독해, 폐쇄형 QA",
      "char_count": 495,
      "word_count": 106,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 30,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nResearch Paper\nDeep reinforcement learning from human preferences (2017)\no 인간 피드백을 이용한 강화 학습(cid:13273)RL(cid:13274)\no 인간 선호도 기반 피드백으로 보상 함수 최적화\no 기존 보상 함수 설계 대신, 인간 피드백을 사용하여 더 나은 성능 달성\no 인간 피드백을 통한 RL의 효율성 입증\no 실제 환경에서의 복잡한 작업에 적용 가능성 제시\nChristiano, P. F., Leike, J., Brown, T., Martic, M., Legg, S., & Amodei, D. (2017). Deep reinforcement learning from human\npreferences.Advances in neural information processing systems,30.",
      "char_count": 463,
      "word_count": 82,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 31,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nRLHF (Reinforcement Learning form Human Feedback)\no 인간의 피드백을 활용하여 모델의 응답을 개선\no Instruction Tuning 과 RLHF 와 함께 모델의 성능 향상\no ChatGPT 의 학습 방법",
      "char_count": 172,
      "word_count": 33,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 32,
      "text": "Chapter 03.\nThe Basic Prompt Engineering Techniques\n02. Few(cid:13247)Shot Prompting",
      "char_count": 84,
      "word_count": 10,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 33,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nFew-Shot Prompting\no Zero(cid:13247)shot prompting 은 복잡한 문제 수행에 한계가 있음.\no Few(cid:13247)shot prompting : 언어 모델에게 예제나 시연(cid:13273)Demonstrations(cid:13274) 을 주며 작업을 수행하는 방법\nMann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., ... & Amodei, D. (2020). Language models are few-shot learners.arXivpreprint arXiv:2005.14165.",
      "char_count": 379,
      "word_count": 52,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 34,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nResearch Paper\nOpen AI’s Research: Language Models are Few-Shot Learners (Brown et al. 2020)\no Few-shot prompting 은 모델의 파라미터 수가 충분히 클 때 효과가 있음\n(Touvron et al. 2023, Kaplan et al., 2020)\nX축: 예시의 수 (cid:13273)K(cid:13274)\nY축: 정확도 (cid:13273)(cid:13984)(cid:13274)\nMann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., ... & Amodei, D. (2020). Language models are few-shot learners.arXivpreprint arXiv:2005.14165.",
      "char_count": 468,
      "word_count": 69,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 35,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nExample\nü 어렵고 복잡한 과제일수록, 예제를 많이 사용하여 해결 할 수 있다.\nPrompt:\nA \"whatpu\" is a small, furry animal native to Tanzania.\nAn example of a sentence that uses the word whatpu is:\nWe were traveling in Africaand we saw these very cute whatpus.\nTo do a \"farduddle\" means to jump up and down really fast.\nAn example of a sentence that uses the word farduddle is:\nOutput:\nWhen we won the game, we all started to farduddle in celebration.\nMann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., ... & Amodei, D. (2020). Language models are few-shot learners.arXivpreprint arXiv:2005.14165.",
      "char_count": 627,
      "word_count": 109,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 36,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nResearch Paper\no Rethinking the Role of Demonstrations:\nWhat Makes In-Context Learning Work? (2022)\n연구 결과\no 예시 사용\n예시를 사용하면 모델의 성능을 향상 시킴\no 예시의 품질 중요\n정답 라벨 (cid:13273)Gold labels(cid:13274) 가장 좋지만, 랜덤 예시도 모델의 추론에 도움이 됨\no 프롬프트 포맷\n올바른 입력(cid:13258)라벨 형식을 유지하는 것이 중요.\nWork, W. M. I. C. L. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?.",
      "char_count": 396,
      "word_count": 71,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 37,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\no 분류 작업 : 예시의 중요성\n• No demonstrations (cid:13273)예시없음(cid:13274)\n• Demonstrations with gold labels (cid:13273)정답라벨이있는예시(cid:13274)\n• Demonstrations with random labels (cid:13273)랜덤라벨이있는예시(cid:13274)\n• Demonstrations with no input(cid:13247)label format (cid:13273)입력(cid:13247)라벨형식없음(cid:13274)\nX축: 다양한 모델 및 평가 방법 Y축: 모델의 성능을 나타내는 지표\n• Gold labels: 정답 라벨이 있는 예시를 사용한 경우 모델 성능이 가장 높음\n• Random labels: 랜덤 라벨이 있는 예시를 사용해도 예시가 없는 경우보다는 성능이 좋음\n• No input(cid:13247)label format: 입력(cid:13247)라벨 형식을 유지하지 않은 경우 성능이 크게 저하\nWork, W. M. I. C. L. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?.",
      "char_count": 647,
      "word_count": 99,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 38,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\no 멀티 초이스 작업 : 라벨 형식의 중요성\n• Gold labels: 정답라벨이있는예시\n• Random labels: 랜덤라벨이있는예시\n• Format variations without keeping the format:\n• 형식을유지하지않은경우\n• 입력(cid:13247)라벨 형식을 유지하는 것이 모델 성능을 최적화하는 데 필수적\n• 형식을 유지하면 랜덤 라벨을 사용하더라도 좋은 성능을 보일 수 있음\nWork, W. M. I. C. L. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?.",
      "char_count": 360,
      "word_count": 67,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 39,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nFormat Example\nRandom Format\nPrompt: Prompt:\n부정 이건 정말 굉장해! 이건 정말 굉장해! // 부정\n와 정말 나쁘다! 긍정 와 정말 나쁘다! // 긍정\n그 영화 진짜 대박이더라. 그 영화 진짜 대박이더라. // 긍정\n긍정 아우 정말 끔찍해\n아우 정말 끔찍해(cid:13973)(cid:13973)\nOutput: Output:\n부정 부정",
      "char_count": 242,
      "word_count": 50,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 40,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\n실습\nFew-shot prompting\nFew(cid:13247)shot prompting 기법을 사용해서\n(cid:13361)오늘의 일기(cid:13362)를 네 줄 분량으로 작성해보세요\n시작 문장의 포맷대로 출력해야 합니다\n시작 문장\n\"나는 오늘 날씨가 좋아서 산책을 했다. 그리고 __.\"",
      "char_count": 199,
      "word_count": 33,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 41,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\n실습\nFew-shot prompting\n(cid:13361)(cid:13362)(cid:13362) 오늘의 일기를 작성해줘.\n아침, 점심, 저녁, 취침 전 시간에 해당하는 문장을 써줘.\n아래 예시를 참고해서 네 줄 만 써줘(cid:13362)(cid:13362)(cid:13362)\n예시:\n1. 아침: \"나는 오늘 날씨가 좋아서 산책을 했다. 그리고 친구를 만났다.”",
      "char_count": 240,
      "word_count": 40,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 42,
      "text": "Chapter 03. Part 04. 엔지니어링 기법- Basic \n실습 \nChat Presets Save 』 <ノ> \ngpt-3.5-turbo こ Compare Temperature 0.1 \nSYSTEM Maximum Tokens 400 \n463939 오늘의 일기를 작성해줘. 아침, 점심, 저녁, 취침 전 시간에 해당하는 문장을 써줘. 아래 예시를 참고해서 네 줄 만 써 \n줘\".\" \nStop sequences \nEnter sequence and press Tab \n1.아침: \"나는 오늘 날씨가 좋아서 산책을 했다. 그리고 친구를 만났다.\" \nUSER Top P 1 \n점심: \n저녁: \nFrequency penalty 0 \n취침 전 : \nPresence penalty 0 \nASSISTANT \n점심: \"점심에는 샐러드를 먹었는데 맛있어서 기분이 좋았다.\" \n저녁: \"저녁에는 집에서 간단히 요리를 해먹었는데, 푹신한 침대가 그리웠다.\" ☑ API and Playground requests will \n취침 전: \"취침 전에는 책을 읽으며 차 한 잔을 마시고 하루를 마무리했다.\" not be used to train our models. \nLearn more \nFast campus",
      "char_count": 608,
      "word_count": 121,
      "needs_ocr": true,
      "ocr_status": "success"
    },
    {
      "page_num": 43,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\n실습\nFew-shot prompting\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 4, 8, 9, 15, 12, 2, 1.\n답(cid:13205) 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 17, 10, 19, 4, 8, 12, 24.\n답(cid:13205) 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 16, 11, 14, 4, 8, 13, 24.\n답(cid:13205) 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 17, 9, 10, 12, 13, 4, 2.\n답(cid:13205) 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 15, 32, 5, 13, 82, 7, 1.\n답(cid:13205)\nA: 정답입니다. (X)",
      "char_count": 456,
      "word_count": 85,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 44,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nFew-shot Prompting 의 한계\nBut is still not a perfect technique,\n복잡한 추론(cid:13273)Reasoning(cid:13274) 문제는 잘 하지 못함\nü Zero-shot prompting ü Few-shot prompting\nQ: 이 그룹의 홀수를 더하면 짝수가 된다. 이 그룹의 홀수들을 더하면 짝수가 됩니다: 4, 8, 9, 15, 12, 2, 1.\n15, 32, 5, 13, 82, 7, 1. 답: 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 10, 19, 4, 8, 12, 24.\nA: 네, 이 그룹의 홀수들을 더하면 107이 되는데, 답: 참입니다.\n이는 짝수입니다. 이 그룹의 홀수들을 더하면 짝수가 됩니다: 16, 11, 14, 4, 8, 13, 24.\n답: 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 9, 10, 12, 13, 4, 2.\n답: 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 15, 32, 5, 13, 82, 7, 1.\n답:\nA: 정답입니다.",
      "char_count": 576,
      "word_count": 128,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 45,
      "text": "Chapter 03.\nThe Basic Prompt Engineering Techniques\n03. Chain(cid:13247)of(cid:13247)Thought\nPrompting",
      "char_count": 102,
      "word_count": 10,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 46,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nChain-of-Thought Prompting (CoT)\n복잡한 과제 수행을 위해, LLM 에게 더 자세한 안내 문구를 작성해주는 것\no\n복잡한 Task (cid:13273)Arithmetic, commonsense, and symbolic reasoning tasks(cid:13274)에 사용하면 효율적\no\n중간 추론 단계를 거치도록 하는 문장으로 구성\no\n답이 나오는 과정에 대해 설명한 예시를 보여주고,\n문제를 풀기 위한 답을 생성할 때 예시와 같은\n방식으로 LLM 이 설명하도록 하는 방식\nImage Source: https://arxiv.org/pdf/2201.11903",
      "char_count": 361,
      "word_count": 64,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 47,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nChain-of-Thought Prompting\nChain-of-Thought Prompting\nStandard Prompting\n모델입력(cid:13273)ModelInput(cid:13274)\nQ(cid:13205) Roger는 테니스공 5개를 가지고 있습니다. 그는 테니스공 3개가 들어있는 캔을 2개\n모델입력(cid:13273)ModelInput(cid:13274)\n더 삽니다.Roger는 이제 테니스공을 몇 개 가지고 있습니까?\nQ: Roger는 테니스공 5개를 가지고 있습니다. 그는 테니스공 3개가 들어있는\nA(cid:13205)Roger는 5개의 공으로 시작했습니다.테니스공 3개가 들어있는 캔 2개를 더 샀습니다.\n캔을 2개 더 삽니다.Roger는 이제 테니스공을 몇 개 가지고 있습니까?\n5(cid:13992)6(cid:13996)11개.정답은11입니다.\nA:정답은 11입니다.\nQ(cid:13205) 카페테리아에 사과가 23개 있었습니다. 그들은 20개를 점심을 만드는 데 사용했고\n6개를 더 샀습니다.이제 사과가 몇 개 있습니까?\nQ: 카페테리아에 사과가 23개 있었습니다. 그들은 20개를 점심을\n만드는 데 사용했고 6개를 더 샀습니다.이제 사과가 몇 개 있습니까?\nModelOutput\nA:정답은 27입니다.❌\nA(cid:13205) 카페테리아에 원래 사과가 23개 있었습니다. 그들은 20개를 점심을 만드는 데\n사용했습니다. 그래서 23 (cid:13258) 20 (cid:13996) 3개가 남았습니다. 그들은 6개를 더 샀기 때문에,\nModelOutput\n이제 3(cid:13992)6 (cid:13996)9개가 있습니다.정답은 9입니다.✔\nA:정답은 27입니다.❌",
      "char_count": 872,
      "word_count": 137,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 48,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nChain-of-Thought Prompting\nCoT 를 사용하여 다양한 문제를 해결하는 예시\n산술 문제, 상식 추론, 전략적 추론, 스포츠 이해, 날짜\n이해, 감정 이해 등\nImage Source: https://arxiv.org/pdf/2201.11903",
      "char_count": 180,
      "word_count": 30,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 49,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nResearch Paper\nGoogle Research (2022): Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\n- Arithmetic, symbolic, and commonsense reasoning 에서 CoT 기법의 성능 좋음\n수학 단어 문제를 푸는 성능 비교\nY축(cid:13205) 문제 해결 비율(cid:13273)(cid:13984)(cid:13274)\nX축(cid:13205) 모델 및 기법\no 연구 결과\nChain(cid:13247)of(cid:13247)Thought 을 사용했을 때 모델 성능 가장 크게 향상\nFine-tuned GPT-3 175B: 55%\nPaLM 540B (standard prompting): 18%\nPaLM 540B (chain-of-thought prompting): 57%\n§ GSM8K는(cid:13379)Grade School Math 8K(cid:13379)의약자로, 초등학교수준의수학문제를포함하는데이터셋\nFigure 2: PaLM 540B uses chain-\nofthought prompting to achieve new\nstateof-the-art performance on the\nGSM8K benchmark of math word\nproblems. Finetuned GPT-3 and prior\nbest are from Cobbe et al. (2021)\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., ... & Zhou, D. (2022). Chain-of-thought prompting elicits reasoning in\nlarge language models.Advances in neural information processing systems,35, 24824-24837.",
      "char_count": 985,
      "word_count": 138,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 50,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\no Chain(cid:13247)of(cid:13247)thought 은 모델의 파라미터가 클 때 효과적인 기법\nü 일반적인 스케일링 곡선보다 더 높은 성능을 보임.\nFigure 7: Chain-of-thought prompting also improves the commonsense reasoning\nabilities of language models. The language model shown here is PaLM. Prior best\nnumbers are from the leaderboards of CSQA (Talmor et al., 2019) and StrategyQA\n(Gevaet al., 2021) (single-model only, as of May 5, 2022). Additional results using\nvarious sizes of LaMDA, GPT-3, and PaLMare shown in Table 4.\nFigure 4: Chain-of-thought prompting enables large language models to\nsolve challenging math problems. Notably, chain-of-thought reasoning is an\nemergent ability of increasing model scale. Prior best numbers are from\nCobbe et al. (2021) for GSM8K, Jieet al. (2022) for SVAMP, and Lan et al. (2021)\nfor MAWPS.\n(cid:13274)억\n(cid:13205)위단\n,수터미라파(cid:13273)기크델모\n(cid:13205)축X•\n(cid:13274)(cid:13984)(cid:13273)율비결해제문\n(cid:13205)축Y•",
      "char_count": 936,
      "word_count": 134,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 51,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nCoT의 한계점\no 모델의 파라미터 수가 적은 모델에서는 기법의 성능이 떨어짐\no (cid:13361)CoT only yields performance gains when used with models of\n(cid:13973)100B parameters(cid:13362)\no 사람이 직접 사고의 과정을 문장으로 작성해야 하는 번거로움\no 프롬프트의 완성도가 높지 않으면 결과가 좋지 않음",
      "char_count": 253,
      "word_count": 46,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 52,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\n실습\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 4, 8, 9, 15, 12, 2, 1.\n답: 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 10, 19, 4, 8, 12, 24.\n답: 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 16, 11, 14, 4, 8, 13, 24.\n답: 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 9, 10, 12, 13, 4, 2.\n답: 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 15, 32, 5, 13, 82, 7, 1.\n답:\nModel Output: 정답입니다. (X)",
      "char_count": 348,
      "word_count": 84,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 53,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\n실습\n이 그룹의 홀수의 합이 짝수가 된다: 4, 8, 9, 15, 12, 2, 1.\nA: 모든 홀수(cid:13273)9, 15, 1(cid:13274)를 더하면 25입니다.\n정답은 (cid:13379)거짓(cid:13379)입니다.\n이 그룹의 홀수의 합이 짝수가 된다: 17, 10, 19, 4, 8, 12, 24.\nA: 모든 홀수(cid:13273)17, 19(cid:13274)를 더하면 36입니다.\n정답은 (cid:13379)참(cid:13379)입니다.\n이 그룹의 홀수의 합이 짝수가 된다: 16, 11, 14, 4, 8, 13, 24.\nA: 모든 홀수(cid:13273)11, 13(cid:13274)를 더하면 24입니다.\n정답은 (cid:13379)참(cid:13379)입니다.\n이 그룹의 홀수의 합이 짝수가 된다: 17, 9, 10, 12, 13, 4, 2.\nA: 모든 홀수(cid:13273)17, 9, 13(cid:13274)를 더하면 39입니다.\n정답은 (cid:13379)거짓(cid:13379)입니다.\n이 그룹의 홀수의 합이 짝수가 된다: 15, 32, 5, 13, 82, 7, 1.\nA:\nModel Output: A: 모든 홀수(cid:13273)15, 5, 13, 7, 1(cid:13274)를 더하면 41입니다. 홀수입니다. 따라서 정답은 (cid:13379)거짓(cid:13379)입니다.",
      "char_count": 717,
      "word_count": 121,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 54,
      "text": "Chapter 03.\nThe Basic Prompt Engineering Techniques\n04. Zero(cid:13247)Shot\nChain of Thought",
      "char_count": 92,
      "word_count": 12,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 55,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nZero Shot-Chain of Thought\nLarge Language Models are Zero-Shot Reasoners (2022)\n- (cid:13361)단계적으로 생각해봐(cid:13362) (cid:13273)(cid:13362)Let(cid:13364)s Think Step by Step(cid:13362)(cid:13274)\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large language models are zero-shot reasoners.Advances in neural information processing systems,35, 22199-22213.",
      "char_count": 408,
      "word_count": 49,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 56,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nZero Shot-Chain of Thought\nLarge Language Models are Zero-Shot Reasoners (2022)\n- (cid:13361)단계적으로 생각해봐(cid:13362) (cid:13273)(cid:13362)Let(cid:13364)s Think Step by Step(cid:13362)(cid:13274)\no Zero(cid:13247)shot과 Zero(cid:13247)shot(cid:13247)CoT의 성능 비교 o Benchmark, comparing Zero(cid:13247)shot, Few(cid:13247)shot, and\ntheir CoT counterparts\nX축: 모델 크기 (cid:13273)파라미터 수, 단위: 억(cid:13274)\nY축: 문제 해결 비율 (cid:13273)(cid:13984)(cid:13274)\n• GSM8K, 또는Grade School Math 8K,는고품질의초등학교수준수학단어문제로구성된데이터셋\n• GSM8K는총8,500개의문제를포함하고있으며, 이중7,500개는훈련용, 1,000개는테스트용으로나뉨\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large language models are zero-shot reasoners.Advances in neural information processing systems,35, 22199-22213.",
      "char_count": 772,
      "word_count": 85,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 57,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nZero Shot-Chain of Thought\n- “단계적으로 생각해봐 (”Let’s Think Step by Step”)\no More trigger examples",
      "char_count": 128,
      "word_count": 21,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 58,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\n실습\no Zero(cid:13247)Shot Chain of Thought 을 사용해서 이 문제의 정답을 맞춰보세요.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 4, 8, 9, 15, 12, 2, 1.\n답: 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 10, 19, 4, 8, 12, 24.\n답: 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 16, 11, 14, 4, 8, 13, 24.\n답: 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 9, 10, 12, 13, 4, 2.\n답: 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 15, 32, 5, 13, 82, 7, 1.\n답:\nModel Output:",
      "char_count": 400,
      "word_count": 93,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 59,
      "text": "Chapter 03. Part 04. 엔지니어링 기법- Basic \n실습 \nChat Presets Save ↑ <ノ> \ngpt-3.5-turbo こ ◇ Compare Temperature 0.1 \nSYSTEM \nEnter system instructions \nMaximum Tokens 400 \nUSER \nStop sequences \n이 그룹의 홀수들을 더하면 짝수가 됩니다: 4, 8, 9, 15, 12, 2, 1. Enter sequence and press Tab \n답: 거짓입니다. \n이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 10, 19, 4, 8, 12, 24. \n답: 참입니다. \nTop P 1 \n이 그룹의 홀수들을 더하면 짝수가 됩니다: 16, 11, 14, 4, 8, 13, 24. \n답: 참입니다. \n이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 9, 10, 12, 13, 4, 2. Frequency penalty 0 \n답: 거짓입니다. \n이 그룹의 홀수들을 더하면 짝수가 됩니다: 15, 32, 5, 13, 82, 7, 1. \nPresence penalty 0 \n답: \n== Let's think step by step. \n① API and Playground requests will \n-- Answer in Korean \nnot be used to train our models. \nLearn more \nASSISTANT \n이 그룹의 홀수들을 더하면 짝수가 됩니다: 15, 32, 5, 13, 82, 7, 1. \n답: 거짓입니다. \nFast campus",
      "char_count": 777,
      "word_count": 160,
      "needs_ocr": true,
      "ocr_status": "success"
    },
    {
      "page_num": 60,
      "text": "Chapter 03. \nThe Basic Prompt Engineering Techniques \n05. Self-Consistency \nFast campus",
      "char_count": 87,
      "word_count": 11,
      "needs_ocr": true,
      "ocr_status": "success"
    },
    {
      "page_num": 61,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nSelf-Consistency\nSimple Idea: 가장 많은 답이 정답일 확률이 높다\n수학 문제(cid:13205) 10(cid:13992)2(cid:13258)1\n학생 A(cid:13996) 11\n학생 B (cid:13996)11\n학생 C(cid:13996)12\n학생 D(cid:13996) 11\n학생 E(cid:13996)11\n최종 답 (cid:13205) 11",
      "char_count": 241,
      "word_count": 34,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 62,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nSelf-Consistency\no Chain-of-thought prompting 을 개선한 기법\no 다양한 추론 경로를 만들어 그 중에서 가장 일관된 답변을 선택하는 방식\no 복잡한 산술 문제나 논리 문제에 효과적\n1. Chain(cid:13247)of(cid:13247)thought: 문제 제시\n2. Sample(cid:13247)a diverse set of reasoning\npaths: 다양한 추론 경로 샘플링\n3. Marginalize out reasoning paths to\naggregate final answers : 최종답 선택",
      "char_count": 341,
      "word_count": 58,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 63,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nResearch Paper\nSelf-Consistency Improves Chain-of-Thought Reasoning in Language Models (2022)\n세 단계에 걸쳐 진행 o 문제에 대한 여러 추론 경로를 고려하면서, 단일 추론이 갖고 있는 오류가능성을 줄임\no 수학 문제와 같이 정확성을 요구하는 일에서 모델 답변의 정확성을 높일 수 있음\n(cid:13968)1단계(cid:13967) CoT 프롬프트 엔지니어링으로 시작한다. 언어\n모델에게 문제를 해결하는 과정을 단계별로 설명하도록\n하고 있다.\n(cid:13273)예시(cid:13274) 주차장에 3대의 차가 있고 2대가 더 들어오면 총 몇\n대의 차가 있는지 계산하는 문제가 있다. 모델은 있던 차\n3대에 더해진 2대를 더해서 5대가 있다고 답한다. 그리고\n새로운 산술 문제를 풀이하라고 모델에게 요구한다.\n새로운문제: 재닛의 오리들은 하루에 알을 16개 낳는다.\n재닛은 매일 아침 3개의 알을 먹고, 매일 4개의 알을\n머핀을 굽는데 사용한다. 나머지 알은 하나에 2달러씩\n판매한다. 재닛은 매일 얼마를 벌까?\n(cid:13968)2단계(cid:13967) 여러가지경로샘플링: 재닛의 오리들이 하루에\n16개의 알을 낳는다를 가정으로, 새로운 문제에 대한 여러\n계산 경로를 탐색한다. 매일 재밋이 얼마를 버는지를\n맞추기 위한 계산이다.\n(cid:13968)3단계(cid:13967) 모델이 일관된 답변을 도출하기 위해 2단계\n샘플링을 통해 나온 결과를 종합하여 추론한다. 그리고\n가장 많이 생성된 답변인 결과를 내놓는다. (cid:13900)18불이다.\nWang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., ... & Zhou, D. (2022). Self-consistency improves chain of thought reasoning in language models.arXivpreprint arXiv:2203.11171.",
      "char_count": 1023,
      "word_count": 191,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 64,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nSelf-Consistency 성능\no 수학 문제 정답을 맞춘 확률이 높음\no 다수결 투표 방식의 정확도가 높음\no Greedy decode: 단일 경로를 따라 답을 생성\nMethod: 사용된모델과기법\no Weighted avg (cid:13273)unnormalized(cid:13274): 가중 평균을 사용하여 답을 도출\no CoT(cid:13247)prompting: Chain(cid:13247)of(cid:13247)Thought 프롬프팅을 사용한 성능\no Weighted sum (cid:13273)normalized(cid:13274): 정규화된 가중 합을 사용하여 답을 도출U\no Self(cid:13247)consistency: Self(cid:13247)Consistency 기법을 사용한 성능\no weighted sum (cid:13273)majority vote(cid:13274): 다수결 투표 방식",
      "char_count": 495,
      "word_count": 69,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 65,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nResearch Paper\nü 복잡한 추론 작업에서 비용 효율적\nü 다양한 추론 경로를 통한 높은 정확도\nFigure 2: Self-consistency (blue) significantly improves accuracy over CoT-prompting with greedy decoding (orange) across arithmetic and\ncommonsense reasoning tasks, over LaMDA-137B. Sampling a higher number of diverse reasoning paths consistently improves reasoning accuracy.\n§ Self(cid:13247)Consistency의 한계점\no 복잡한 추론 작업을 해결 할 때 비용이 많이 듦\no 복잡한 추론을 해결하려면, 상당한 양의 훈련 데이터 필요. 모델이 일관된 응답을 효과적으로 생성하기 위해\n다양한 추론 패턴을 학습해야 하기 때문\no 프롬프트가 명확하지 않거나 간결하지 않을 때, Self(cid:13247)Consistency의 기법 성능이 저하됨",
      "char_count": 583,
      "word_count": 98,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 66,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\n실습\n아래 텍스트는 소프트회사의 보안관련 이메일입니다.\n이메일 내용 중에서 비즈니스에 중요한 영향을 미치는 내용과 아닌 내용을\nSelf(cid:13247)Consistency Prompting 기법을 사용하여 구분해보세요.\n이메일 내용\n안녕하세요,\n귀사의 시스템에서 중요한 보안 취약점을 발견하게 되어 이와 관련된 사항을 공유하고자 합니다.\n이 취약점은 악용이 쉽지 않지만, 이를 통해 모든 사용자 데이터에 접근할 수 있는 가능성이\n있습니다. 이에 대한 증거로 개념 증명 파일을 첨부했으니 확인해 주시기 바랍니다.\n이 문제는 매우 심각하며, 조속한 시일 내에 해결해 주실 것을 요청드립니다.\n해당 취약점을 통해 발생할 수 있는 잠재적 위협을 방지하기 위해, 귀사의 보안 팀에서 신속하게\n대응해 주시기를 바랍니다. 추가적인 정보가 필요하거나, 제가 더 도울 수 있는 부분이 있다면\n언제든지 연락해 주시기 바랍니다.빠른 시일 내에 문제 해결을 부탁드리며, 이러한 문제를 미리\n발견하게 되어 다행이라고 생각합니다.\n귀사의 보안 강화를 위해 함께 협력할 수 있기를 기대합니다.\n감사합니다.",
      "char_count": 584,
      "word_count": 130,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 67,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\n실습\nGenerated by gpt(cid:13247)3.5(cid:13247)turbo\nTemp: 0.3",
      "char_count": 94,
      "word_count": 11,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 68,
      "text": "Chapter 03. Part 04. 엔지니어링 기법- Basic \n1번 ASSISTANT \n{Important} : { 보안 취약점 발견, 모든 사용자 데이터에 접근 가능성, 증거 첨부, 심각성 강조, 조속한 대응 요청, 보안 팀 대 \n응 요청, 잠재적 위협 방지, 협력 요청} \n{Not Important} : { 인사말, 도움 제안, 다행이라는 감사 표현 } \n2번 ASSISTANT \n{Important} : { 보안 취약점 발견, 모든 사용자 데이터에 접근 가능성, 증거 첨부, 문제 심각성 강조, 조속한 대응 요청, 보안 \n팀 대응 요청, 잠재적 위협 방지, 보안 강화 협력 요청} \n{Not Important} : { 이메일의 시작 및 인사말, 추가적인 정보 및 도움 제안, 다행이라는 감사 표현} \n3번 ASSISTANT \n{Important} : { 보안 취약점 발견, 모든 사용자 데이터에 접근 가능성, 증거 첨부, 심각한 문제, 조속한 대응 요청, 잠재적 위 \n협 방지, 보안 팀 대응 요청, 문제 해결 요청, 보안 강화 협력 요청 } \n{Not Important} : { 개념 증명 파일 첨부, 추가 정보 및 도움 제공 가능 여부, 미리 발견해서 다행이라는 감사 인사} \nFast campus",
      "char_count": 623,
      "word_count": 154,
      "needs_ocr": true,
      "ocr_status": "success"
    },
    {
      "page_num": 69,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\n학습 목표\nü01\n프롬프트 엔지니어링 기초 기법을 이해한다.\n02\n연구 논문을 통해 각 프롬프트 엔지니어링 기법의 핵심과 한계를 이해한다.\n03\n실습을 통해 각 프롬프트 엔지니어링 방법을 학습한다.",
      "char_count": 145,
      "word_count": 32,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 70,
      "text": "Chapter 03. Part 04. 엔지니어링기법-Basic\nReferences\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language\nmodels are few-shot learners. Advances in Neural Information Processing Systems, 33, 1877-1 901.\nChristiano, P. F., Leike, J., Brown, T., Martic, M., Legg, S., & Amodei, D. (2017). Deep reinforcement learning from\nhuman preferences. Advances in Neural Information Processing Systems, 30.\nMann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., ... & Amodei, D. (2020). Language\nmodels are few-shot learners. arXiv preprint arXiv:2005.14165.\nWang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., ... & Zhou, D. (2022). Self-consistency improves chain\nof thought reasoning in language models. arXiv preprint arXiv:2203.11171.\nWork, W. M. I. C. L. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?.\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., ... & Zhou, D. (2022). Chain-of-thought prompting\nelicits reasoning in large language models. Advances in Neural Information Processing Systems, 35,\n24824-24837.",
      "char_count": 1132,
      "word_count": 169,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    }
  ]
}
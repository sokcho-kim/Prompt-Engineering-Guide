{
  "source": "Part 4. 프롬프트 제작의 기초 - 핵심 원리와 방법론 (Chapter 2).pdf",
  "parsed_at": "2026-01-09T17:58:08.868352",
  "total_pages": 54,
  "pages_with_text": 48,
  "pages_needing_ocr": 6,
  "ocr_page_numbers": [
    4,
    26,
    43,
    44,
    51,
    52
  ],
  "pages": [
    {
      "page_num": 1,
      "text": "국내 공채 1호 프롬프트 엔지니어 강수진의\n프롬프트 엔지니어링 A to Z\nPrompt Engineering",
      "char_count": 60,
      "word_count": 13,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 2,
      "text": "Chapter 03. Part 04.\nPrompt Engineering Techniques\nLevel : Basic (cid:13249) Advanced (cid:13247) Applications",
      "char_count": 110,
      "word_count": 14,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 3,
      "text": "Chapter 2\nTaxonomy of Prompt Engineering Techniques\nAdvanced\nBasic Applications\n• Generate Knowledge Prompting, •데이터생성과분류하기\n•Zero-Shot Prompting Prompt Chaining, Tree of Thoughts\n•코드생성하기\n•Few-Shot Prompting • Retrieval Augmented Generation,\n•펑션콜함수\nAutomatic Prompt Engineer,\n•Chain-of-Thought Prompting\nActive-Prompt, Directional Stimulus\n•Self-consistency Prompting, React",
      "char_count": 373,
      "word_count": 41,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 4,
      "text": "Chapter 03 \nPrompt Engineering Techniques \nBasic \nFast campus",
      "char_count": 61,
      "word_count": 8,
      "needs_ocr": true,
      "ocr_status": "success"
    },
    {
      "page_num": 5,
      "text": "Course Objectives & Learning Outcomes\n학습 목표\nü01\n프롬프트 엔지니어링 기초 기법을 이해한다.\n02\n연구 논문을 통해 각 프롬프트 엔지니어링 기법의 핵심과 한계를 이해한다.\n03\n실습을 통해 각 프롬프트 엔지니어링 방법을 학습한다.",
      "char_count": 148,
      "word_count": 32,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 6,
      "text": "Table of Contents\n01 Zero-Shot Prompting\n02 Few-Shot Prompting\n03 Chain-of-Thought Prompting\n04 Self-Consistency",
      "char_count": 112,
      "word_count": 14,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 7,
      "text": "Chapter 03.\nThe Basic Prompt Engineering Techniques\n01. Zero(cid:13247)Shot Prompting\no Instruction-Tuning\no RLHF (Reinforcement Learning form Human Feedback)",
      "char_count": 158,
      "word_count": 19,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 8,
      "text": "Chapter 3. 프롬프트엔지니어링기초\nResearch Paper\nOpen AI : Language Models are Few-shot Learners (2020)\nFigure 2.1: Zero-shot, one-shot and few-shot, contrasted with\ntraditional fine-tuning. The panels above show four methods for\nperforming a task with a language model – fine-tuning is the\ntraditional method, whereas zero-, one-, and few-shot, which we\nstudy in this work, require the model to perform the task with only\nforward passes at test time. We typically present the model with a\nfew dozen examples in the few shot setting.\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners.Advances in neural information processing systems,33,\n1877-1901.",
      "char_count": 724,
      "word_count": 113,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 9,
      "text": "Chapter 3. 프롬프트엔지니어링기초\nZero-Shot Prompting\no 언어 모델에게 예제나 시연(cid:13273)Demonstrations(cid:13274) 을 주지 않고 작업을 수행하는 방법\no 언어 모델이 기존 지식을 사용하여 작업을 추론함\no 대량의 데이터를 사전 학습 했기 때문에 가능\n제로샷 프롬프트는 언어 모델의 강력한 기능 중 하나\n최소한의 정보만으로도 다양한 작업을 수행할 수 있음\n이 기술은 특히 데이터가 부족한 상황에서 유용하게 활용됨",
      "char_count": 261,
      "word_count": 55,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 10,
      "text": "Chapter 3. 프롬프트엔지니어링기초\nExample\no Text Classification o Translation o Closed Question Answering\nPrompt: Prompt: Prompt:\n다음 텍스트에서 긍정, 부정, 중립 중 다음 한국어 단어를 영어로 번역해줘. 대한민국의 수도는 서울이야?\n하나로 분류해.\n단어(cid:13205) 인공 눈물\n텍스트(cid:13205) 나는 마라탕 맛이 그저 그랬어.\nSentiment:",
      "char_count": 250,
      "word_count": 42,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 11,
      "text": "Chapter 3. 프롬프트엔지니어링기초\no 제로샷 프롬프팅의 작동 방식\no 텍스트와 분류 예시를 모델에게 제공하지 않았는데도 정답을 맞춤",
      "char_count": 77,
      "word_count": 17,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 12,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nResearch Paper\nFINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS (2022)\no 연구 개요: 대형 언어 모델의 제로 샷 학습 능력을 개선법 연구\n자연어 지시로 60개 이상의 NLP 데이터셋에 대해 137B 파라미터 모델을 미세 조정\no 연구 결과 : 모델 FLAN은 제로샷 성능에서 기본 모델보다 우수함\nInstruction Tuning 은 사전 학습 데이터 없이도 NLP 데이터셋에서 모델의 성능을 올림\nInstruction Tuning\no 기술 개요\no 기술의 장점\no 언어 모델의 제로 샷 능력을 향상 시키기 위한 기술 o Instruction tuning 은 모델 크기가 충분할 때 효과적\no Instruction Tuning은 대형 언어 모델이 다양한 작업을 수행할 수 있도록 함\no 지시에 따라 모델의 응답을 미세 조정할 수 있음\no 다수의 작업 클러스터에서 Instruction tuning 시 (cid:13278)모델이 해보지 않은\no 챗봇이 더 정확하고 좋은 결과물을 얻어냄\n작업에 대한 성능 향상\n* 137B 는(cid:13361)B(cid:13362)는billion을의미한다.\nWei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B., ... & Le, Q. V. (2021). Finetuned language models are zero-shot learners.arXivpreprint arXiv:2109.01652.",
      "char_count": 779,
      "word_count": 158,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 13,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\n다양한 NLP 작업에서 우수한 성능을 보여주는 그래프\no FLAN 137B는 Zero(cid:13247)shot prompting 성능에서 다른 대형\n언어 모델들보다 전반적으로 더 우수한 성능을 보임.\no 자연어 추론\nFLAN 137B는 대부분의 작업에서 다른 모델보다 성능 좋음\no 독해\n여러 모델이 유사한 성능을 보이지만, FLAN 137B는 여전히 우수한 성능을 보임\no 폐쇄형 QA\nFLAN 137B와 다른 모델들이 유사한 성능을 보이는 작업도\n있지만, FLAN 137B가 더 좋은 성능을 보이는 작업도 있음\no 번역\nFLAN 137B는 몇 가지 번역 작업에서 다른 모델들보다 성능이 뛰어남\n• X축 (cid:13273)가로축(cid:13274): 제로샷 성능, 값이 클수록 성능이 좋음\n• Y축 (cid:13273)세로축(cid:13274): 테스트된 작업의 유형\n• 작업 유형: 자연어 추론, 독해, 폐쇄형 QA",
      "char_count": 484,
      "word_count": 104,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 14,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nResearch Paper\nDeep reinforcement learning from human preferences (2017)\no 인간 피드백을 이용한 강화 학습(cid:13273)RL(cid:13274)\no 인간 선호도 기반 피드백으로 보상 함수 최적화\no 기존 보상 함수 설계 대신, 인간 피드백을 사용하여 더 나은 성능 달성\no 인간 피드백을 통한 RL의 효율성 입증\no 실제 환경에서의 복잡한 작업에 적용 가능성 제시\nChristiano, P. F., Leike, J., Brown, T., Martic, M., Legg, S., & Amodei, D. (2017). Deep reinforcement learning from human\npreferences.Advances in neural information processing systems,30.",
      "char_count": 452,
      "word_count": 80,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 15,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nRLHF (Reinforcement Learning form Human Feedback)\no 인간의 피드백을 활용하여 모델의 응답을 개선\no Instruction Tuning 과 RLHF 와 함께 모델의 성능 향상\no ChatGPT 의 학습 방법",
      "char_count": 161,
      "word_count": 31,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 16,
      "text": "Chapter 03.\nThe Basic Prompt Engineering Techniques\n02. Few(cid:13247)Shot Prompting",
      "char_count": 84,
      "word_count": 10,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 17,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nFew-Shot Prompting\no Zero(cid:13247)shot prompting 은 복잡한 문제 수행에 한계가 있음.\no Few(cid:13247)shot prompting : 언어 모델에게 예제나 시연(cid:13273)Demonstrations(cid:13274) 을 주며 작업을 수행하는 방법\nMann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., ... & Amodei, D. (2020). Language models are few-shot learners.arXivpreprint arXiv:2005.14165.",
      "char_count": 368,
      "word_count": 50,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 18,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nResearch Paper\nOpen AI’s Research: Language Models are Few-Shot Learners (Brown et al. 2020)\no Few-shot prompting 은 모델의 파라미터 수가 충분히 클 때 효과가 있음\n(Touvron et al. 2023, Kaplan et al., 2020)\nX축: 예시의 수 (cid:13273)K(cid:13274)\nY축: 정확도 (cid:13273)(cid:13984)(cid:13274)\nMann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., ... & Amodei, D. (2020). Language models are few-shot learners.arXivpreprint arXiv:2005.14165.",
      "char_count": 457,
      "word_count": 67,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 19,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nExample\nü 어렵고 복잡한 과제일수록, 예제를 많이 사용하여 해결 할 수 있다.\nPrompt:\nA \"whatpu\" is a small, furry animal native to Tanzania.\nAn example of a sentence that uses the word whatpu is:\nWe were traveling in Africaand we saw these very cute whatpus.\nTo do a \"farduddle\" means to jump up and down really fast.\nAn example of a sentence that uses the word farduddle is:\nOutput:\nWhen we won the game, we all started to farduddle in celebration.\nMann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., ... & Amodei, D. (2020). Language models are few-shot learners.arXivpreprint arXiv:2005.14165.",
      "char_count": 616,
      "word_count": 107,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 20,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nResearch Paper\no Rethinking the Role of Demonstrations:\nWhat Makes In-Context Learning Work? (2022)\n연구 결과\no 예시 사용\n예시를 사용하면 모델의 성능을 향상 시킴\no 예시의 품질 중요\n정답 라벨 (cid:13273)Gold labels(cid:13274) 가장 좋지만, 랜덤 예시도 모델의 추론에 도움이 됨\no 프롬프트 포맷\n올바른 입력(cid:13258)라벨 형식을 유지하는 것이 중요.\nWork, W. M. I. C. L. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?.",
      "char_count": 385,
      "word_count": 69,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 21,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\no 분류 작업 : 예시의 중요성\n• No demonstrations (cid:13273)예시없음(cid:13274)\n• Demonstrations with gold labels (cid:13273)정답라벨이있는예시(cid:13274)\n• Demonstrations with random labels (cid:13273)랜덤라벨이있는예시(cid:13274)\n• Demonstrations with no input(cid:13247)label format (cid:13273)입력(cid:13247)라벨형식없음(cid:13274)\nX축: 다양한 모델 및 평가 방법 Y축: 모델의 성능을 나타내는 지표\n• Gold labels: 정답 라벨이 있는 예시를 사용한 경우 모델 성능이 가장 높음\n• Random labels: 랜덤 라벨이 있는 예시를 사용해도 예시가 없는 경우보다는 성능이 좋음\n• No input(cid:13247)label format: 입력(cid:13258)라벨 형식을 유지하지 않은 경우 성능이 크게 저하\nWork, W. M. I. C. L. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?.",
      "char_count": 636,
      "word_count": 97,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 22,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\no 멀티 초이스 작업 (cid:13205) 라벨 형식의 중요성\n• Gold labels: 정답라벨이있는예시\n• Random labels: 랜덤라벨이있는예시\n• Format variations without keeping the format:\n• 형식을유지하지않은경우\n• 입력(cid:13247)라벨 형식을 유지하는 것이 모델 성능을 최적화하는 데 필수적\n• 형식을 유지하면 랜덤 라벨을 사용하더라도 좋은 성능을 보일 수 있음\nWork, W. M. I. C. L. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?.",
      "char_count": 359,
      "word_count": 65,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 23,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nFormat Example\nRandom Format\nPrompt: Prompt:\n부정 이건 정말 굉장해! 이건 정말 굉장해! // 부정\n와 정말 나쁘다! 긍정 와 정말 나쁘다! // 긍정\n그 영화 진짜 대박이더라. 그 영화 진짜 대박이더라. // 긍정\n긍정 아우 정말 끔찍해\n아우 정말 끔찍해(cid:14004)(cid:14004)\nOutput: Output:\n부정 부정",
      "char_count": 231,
      "word_count": 48,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 24,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\n실습\nFew-shot prompting\nFew(cid:13247)shot prompting 기법을 사용해서\n(cid:13361)오늘의 일기(cid:13362)를 네 줄 분량으로 작성해보세요\n시작 문장의 포맷대로 출력해야 합니다\n시작 문장\n\"나는 오늘 날씨가 좋아서 산책을 했다. 그리고 __.\"",
      "char_count": 188,
      "word_count": 31,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 25,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\n실습\nFew-shot prompting\n(cid:13361)(cid:13362)(cid:13362) 오늘의 일기를 작성해줘.\n아침, 점심, 저녁, 취침 전 시간에 해당하는 문장을 써줘.\n아래 예시를 참고해서 네 줄 만 써줘(cid:13362)(cid:13362)(cid:13362)\n예시:\n1. 아침: \"나는 오늘 날씨가 좋아서 산책을 했다. 그리고 친구를 만났다.”",
      "char_count": 229,
      "word_count": 38,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 26,
      "text": "Chapter 3. 프롬프트 엔지니어링 기초. \n실습 \nChat Presets Save 』 <ノ> \ngpt-3.5-turbo こ Compare Temperature 0.1 \nSYSTEM Maximum Tokens 400 \n463939 오늘의 일기를 작성해줘. 아침, 점심, 저녁, 취침 전 시간에 해당하는 문장을 써줘. 아래 예시를 참고해서 네 줄 만 써 \n줘\".\" \nStop sequences \nEnter sequence and press Tab \n1.아침: \"나는 오늘 날씨가 좋아서 산책을 했다. 그리고 친구를 만났다.\" \nUSER Top P 1 \n점심: \n저녁: \nFrequency penalty 0 \n취침 전 : \nPresence penalty 0 \nASSISTANT \n점심: \"점심에는 샐러드를 먹었는데 맛있어서 기분이 좋았다.\" \n저녁: \"저녁에는 집에서 간단히 요리를 해먹었는데, 푹신한 침대가 그리웠다.\" ☑ API and Playground requests will \n취침 전: \"취침 전에는 책을 읽으며 차 한 잔을 마시고 하루를 마무리했다.\" not be used to train our models. \nLearn more \nFast campus",
      "char_count": 597,
      "word_count": 119,
      "needs_ocr": true,
      "ocr_status": "success"
    },
    {
      "page_num": 27,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\n실습\nFew-shot prompting\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 4, 8, 9, 15, 12, 2, 1.\n답(cid:13205) 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 17, 10, 19, 4, 8, 12, 24.\n답(cid:13205) 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 16, 11, 14, 4, 8, 13, 24.\n답(cid:13205) 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 17, 9, 10, 12, 13, 4, 2.\n답(cid:13205) 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 15, 32, 5, 13, 82, 7, 1.\n답(cid:13205)\nA: 정답입니다. (X)",
      "char_count": 445,
      "word_count": 83,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 28,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nFew-shot Prompting 의 한계\nBut is still not a perfect technique,\n복잡한 추론(cid:13273)Reasoning(cid:13274) 문제는 잘 하지 못함\nü Zero-shot prompting ü Few-shot prompting\nQ: 이 그룹의 홀수를 더하면 짝수가 된다. 이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 4, 8, 9, 15, 12, 2, 1.\n15, 32, 5, 13, 82, 7, 1. 답(cid:13205) 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 17, 10, 19, 4, 8, 12, 24.\nA: 네, 이 그룹의 홀수들을 더하면 107이 되는데, 답(cid:13205) 참입니다.\n이는 짝수입니다. 이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 16, 11, 14, 4, 8, 13, 24.\n답(cid:13205) 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 17, 9, 10, 12, 13, 4, 2.\n답(cid:13205) 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 15, 32, 5, 13, 82, 7, 1.\n답(cid:13205)\nA(cid:13205) 정답입니다.",
      "char_count": 675,
      "word_count": 126,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 29,
      "text": "Chapter 03.\nThe Basic Prompt Engineering Techniques\n03. Chain(cid:13247)of(cid:13247)Thought\nPrompting",
      "char_count": 102,
      "word_count": 10,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 30,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nChain-of-Thought Prompting (CoT)\n복잡한 과제 수행을 위해, LLM 에게 더 자세한 안내 문구를 작성해주는 것\no\n복잡한 Task (cid:13273)Arithmetic, commonsense, and symbolic reasoning tasks(cid:13274)에 사용하면 효율적\no\n중간 추론 단계를 거치도록 하는 문장으로 구성\no\n답이 나오는 과정에 대해 설명한 예시를 보여주고,\n문제를 풀기 위한 답을 생성할 때 예시와 같은\n방식으로 LLM 이 설명하도록 하는 방식\nImage Source: https://arxiv.org/pdf/2201.11903",
      "char_count": 350,
      "word_count": 62,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 31,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nChain-of-Thought Prompting\nChain-of-Thought Prompting\nStandard Prompting\n모델입력(cid:13273)ModelInput(cid:13274)\nQ(cid:13205) Roger는 테니스공 5개를 가지고 있습니다. 그는 테니스공 3개가 들어있는 캔을 2개\n모델입력(cid:13273)ModelInput(cid:13274)\n더 삽니다.Roger는 이제 테니스공을 몇 개 가지고 있습니까?\nQ(cid:13205) Roger는 테니스공 5개를 가지고 있습니다. 그는 테니스공 3개가 들어있는\nA(cid:13205)Roger는 5개의 공으로 시작했습니다.테니스공 3개가 들어있는 캔 2개를 더 샀습니다.\n캔을 2개 더 삽니다.Roger는 이제 테니스공을 몇 개 가지고 있습니까?\n5(cid:13992)6(cid:13996)11개.정답은11입니다.\nA(cid:13205)정답은 11입니다.\nQ(cid:13205) 카페테리아에 사과가 23개 있었습니다. 그들은 20개를 점심을 만드는 데 사용했고\n6개를 더 샀습니다.이제 사과가 몇 개 있습니까?\nQ(cid:13205) 카페테리아에 사과가 23개 있었습니다. 그들은 20개를 점심을\n만드는 데 사용했고 6개를 더 샀습니다.이제 사과가 몇 개 있습니까?\nModelOutput\nA(cid:13205)정답은 27입니다.❌\nA(cid:13205) 카페테리아에 원래 사과가 23개 있었습니다. 그들은 20개를 점심을 만드는 데\n사용했습니다. 그래서 23 (cid:13258) 20 (cid:13996) 3개가 남았습니다. 그들은 6개를 더 샀기 때문에,\nModelOutput\n이제 3(cid:13992)6 (cid:13996)9개가 있습니다.정답은 9입니다.✔\nA(cid:13205)정답은 27입니다.❌",
      "char_count": 911,
      "word_count": 135,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 32,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nChain-of-Thought Prompting\nCoT 를 사용하여 다양한 문제를 해결하는 예시\n산술 문제, 상식 추론, 전략적 추론, 스포츠 이해, 날짜\n이해, 감정 이해 등\nImage Source: https://arxiv.org/pdf/2201.11903",
      "char_count": 169,
      "word_count": 28,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 33,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nResearch Paper\nGoogle Research (2022): Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\n- Arithmetic, symbolic, and commonsense reasoning 에서 CoT 기법의 성능 좋음\n수학 단어 문제를 푸는 성능 비교\nY축(cid:13205) 문제 해결 비율(cid:13273)(cid:13984)(cid:13274)\nX축(cid:13205) 모델 및 기법\no 연구 결과\nChain(cid:13247)of(cid:13247)Thought 을 사용했을 때 모델 성능 가장 크게 향상\nFine-tuned GPT-3 175B: 55%\nPaLM 540B (standard prompting): 18%\nPaLM 540B (chain-of-thought prompting): 57%\n§ GSM8K는(cid:13379)Grade School Math 8K(cid:13379)의약자로, 초등학교수준의수학문제를포함하는데이터셋\nFigure 2: PaLM 540B uses chain-\nofthought prompting to achieve new\nstateof-the-art performance on the\nGSM8K benchmark of math word\nproblems. Finetuned GPT-3 and prior\nbest are from Cobbe et al. (2021)\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., ... & Zhou, D. (2022). Chain-of-thought prompting elicits reasoning in\nlarge language models.Advances in neural information processing systems,35, 24824-24837.",
      "char_count": 974,
      "word_count": 136,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 34,
      "text": "o Chain(cid:13247)of(cid:13247)thought 은 모델의 파라미터가 클 때 효과적인 기법\nü 일반적인 스케일링 곡선보다 더 높은 성능을 보임.\nFigure 7: Chain-of-thought prompting also improves the commonsense reasoning\nabilities of language models. The language model shown here is PaLM. Prior best\nnumbers are from the leaderboards of CSQA (Talmor et al., 2019) and StrategyQA\n(Gevaet al., 2021) (single-model only, as of May 5, 2022). Additional results using\nvarious sizes of LaMDA, GPT-3, and PaLMare shown in Table 4.\nFigure 4: Chain-of-thought prompting enables large language models to\nsolve challenging math problems. Notably, chain-of-thought reasoning is an\nemergent ability of increasing model scale. Prior best numbers are from\nCobbe et al. (2021) for GSM8K, Jieet al. (2022) for SVAMP, and Lan et al. (2021)\nfor MAWPS.\n(cid:13274)억\n(cid:13205)위단\n,수터미라파(cid:13273)기크델모\n(cid:13205)축X•\n(cid:13274)(cid:13984)(cid:13273)율비결해제문\n(cid:13205)축Y•\nChapter 3. 프롬프트엔지니어링기초.",
      "char_count": 925,
      "word_count": 132,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 35,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nCoT의 한계점\no 모델의 파라미터 수가 적은 모델에서는 기법의 성능이 떨어짐\no (cid:13361)CoT only yields performance gains when used with models of\n(cid:14004)100B parameters(cid:13362)\no 사람이 직접 사고의 과정을 문장으로 작성해야 하는 번거로움\no 프롬프트의 완성도가 높지 않으면 결과가 좋지 않음",
      "char_count": 242,
      "word_count": 44,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 36,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\n실습\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 4, 8, 9, 15, 12, 2, 1.\n답: 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 10, 19, 4, 8, 12, 24.\n답: 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 16, 11, 14, 4, 8, 13, 24.\n답: 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 9, 10, 12, 13, 4, 2.\n답: 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다: 15, 32, 5, 13, 82, 7, 1.\n답:\nModel Output: 정답입니다. (X)",
      "char_count": 337,
      "word_count": 82,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 37,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\n실습\n이 그룹의 홀수의 합이 짝수가 된다: 4, 8, 9, 15, 12, 2, 1.\nA: 모든 홀수(cid:13273)9, 15, 1(cid:13274)를 더하면 25입니다.\n정답은 (cid:13379)거짓(cid:13379)입니다.\n이 그룹의 홀수의 합이 짝수가 된다: 17, 10, 19, 4, 8, 12, 24.\nA: 모든 홀수(cid:13273)17, 19(cid:13274)를 더하면 36입니다.\n정답은 (cid:13379)참(cid:13379)입니다.\n이 그룹의 홀수의 합이 짝수가 된다: 16, 11, 14, 4, 8, 13, 24.\nA: 모든 홀수(cid:13273)11, 13(cid:13274)를 더하면 24입니다.\n정답은 (cid:13379)참(cid:13379)입니다.\n이 그룹의 홀수의 합이 짝수가 된다: 17, 9, 10, 12, 13, 4, 2.\nA: 모든 홀수(cid:13273)17, 9, 13(cid:13274)를 더하면 39입니다.\n정답은 (cid:13379)거짓(cid:13379)입니다.\n이 그룹의 홀수의 합이 짝수가 된다: 15, 32, 5, 13, 82, 7, 1.\nA:\nModel Output: A: 모든 홀수(cid:13273)15, 5, 13, 7, 1(cid:13274)를 더하면 41입니다. 홀수입니다. 따라서 정답은 (cid:13379)거짓(cid:13379)입니다.",
      "char_count": 706,
      "word_count": 119,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 38,
      "text": "Chapter 03.\nThe Basic Prompt Engineering Techniques\n04. Zero(cid:13247)Shot\nChain of Thought",
      "char_count": 92,
      "word_count": 12,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 39,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nZero Shot-Chain of Thought\nLarge Language Models are Zero-Shot Reasoners (2022)\n- (cid:13361)단계적으로 생각해봐(cid:13362) (cid:13273)(cid:13362)Let(cid:13364)s Think Step by Step(cid:13362)(cid:13274)\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large language models are zero-shot reasoners.Advances in neural information processing systems,35, 22199-22213.",
      "char_count": 397,
      "word_count": 47,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 40,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nZero Shot-Chain of Thought\nLarge Language Models are Zero-Shot Reasoners (2022)\n- (cid:13361)단계적으로 생각해봐(cid:13362) (cid:13273)(cid:13362)Let(cid:13364)s Think Step by Step(cid:13362)(cid:13274)\no Zero(cid:13247)shot과 Zero(cid:13247)shot(cid:13247)CoT의 성능 비교 o Benchmark, comparing Zero(cid:13247)shot, Few(cid:13247)shot, and\ntheir CoT counterparts\nX축: 모델 크기 (cid:13273)파라미터 수, 단위: 억(cid:13274)\nY축: 문제 해결 비율 (cid:13273)(cid:13984)(cid:13274)\n• GSM8K, 또는Grade School Math 8K,는고품질의초등학교수준수학단어문제로구성된데이터셋\n• GSM8K는총8,500개의문제를포함하고있으며, 이중7,500개는훈련용, 1,000개는테스트용으로나뉨\nKojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large language models are zero-shot reasoners.Advances in neural information processing systems,35, 22199-22213.",
      "char_count": 761,
      "word_count": 83,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 41,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nZero Shot-Chain of Thought\n- “단계적으로 생각해봐 (”Let’s Think Step by Step”)\no More trigger examples",
      "char_count": 117,
      "word_count": 19,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 42,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\n실습\no Zero(cid:13247)Shot Chain of Thought 을 사용해서 이 문제의 정답을 맞춰보세요.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 4, 8, 9, 15, 12, 2, 1.\n답(cid:13205) 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 17, 10, 19, 4, 8, 12, 24.\n답(cid:13205) 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 16, 11, 14, 4, 8, 13, 24.\n답(cid:13205) 참입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 17, 9, 10, 12, 13, 4, 2.\n답(cid:13205) 거짓입니다.\n이 그룹의 홀수들을 더하면 짝수가 됩니다(cid:13205) 15, 32, 5, 13, 82, 7, 1.\n답(cid:13205)\nModel Output:",
      "char_count": 489,
      "word_count": 91,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 43,
      "text": "Chapter 3. 프롬프트 엔지니어링 기초. \n실습 \nChat Presets Save ↑ <ノ> \ngpt-3.5-turbo こ ◇ Compare Temperature 0.1 \nSYSTEM \nEnter system instructions \nMaximum Tokens 400 \nUSER \nStop sequences \n이 그룹의 홀수들을 더하면 짝수가 됩니다: 4, 8, 9, 15, 12, 2, 1. Enter sequence and press Tab \n답: 거짓입니다. \n이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 10, 19, 4, 8, 12, 24. \n답: 참입니다. \nTop P 1 \n이 그룹의 홀수들을 더하면 짝수가 됩니다: 16, 11, 14, 4, 8, 13, 24. \n답: 참입니다. \n이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 9, 10, 12, 13, 4, 2. Frequency penalty 0 \n답: 거짓입니다. \n이 그룹의 홀수들을 더하면 짝수가 됩니다: 15, 32, 5, 13, 82, 7, 1. \nPresence penalty 0 \n답: \n-- Let's think step by step. \n① API and Playground requests will \n-- Answer in Korean \nnot be used to train our models. \nLearn more \nASSISTANT \n이 그룹의 홀수들을 더하면 짝수가 됩니다: 15, 32, 5, 13, 82, 7, 1. \n답: 거짓입니다. \nFast campus",
      "char_count": 766,
      "word_count": 158,
      "needs_ocr": true,
      "ocr_status": "success"
    },
    {
      "page_num": 44,
      "text": "Chapter 03. \nThe Basic Prompt Engineering Techniques \n05. Self-Consistency \nFast campus",
      "char_count": 87,
      "word_count": 11,
      "needs_ocr": true,
      "ocr_status": "success"
    },
    {
      "page_num": 45,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nSelf-Consistency\nSimple Idea: 가장 많은 답이 정답일 확률이 높다\n수학 문제(cid:13205) 10(cid:13992)2(cid:13258)1\n학생 A(cid:13996) 11\n학생 B (cid:13996)11\n학생 C(cid:13996)12\n학생 D(cid:13996) 11\n학생 E(cid:13996)11\n최종 답 (cid:13205) 11",
      "char_count": 230,
      "word_count": 32,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 46,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nSelf-Consistency\no Chain-of-thought prompting 을 개선한 기법\no 다양한 추론 경로를 만들어 그 중에서 가장 일관된 답변을 선택하는 방식\no 복잡한 산술 문제나 논리 문제에 효과적\n1. Chain(cid:13247)of(cid:13247)thought: 문제 제시\n2. Sample(cid:13247)a diverse set of reasoning\npaths: 다양한 추론 경로 샘플링\n3. Marginalize out reasoning paths to\naggregate final answers : 최종답 선택",
      "char_count": 330,
      "word_count": 56,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 47,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nResearch Paper\nSelf-Consistency Improves Chain-of-Thought Reasoning in Language Models (2022)\n세 단계에 걸쳐 진행 o 문제에 대한 여러 추론 경로를 고려하면서, 단일 추론이 갖고 있는 오류가능성을 줄임\no 수학 문제와 같이 정확성을 요구하는 일에서 모델 답변의 정확성을 높일 수 있음\n(cid:13968)1단계(cid:13967) CoT 프롬프트 엔지니어링으로 시작한다. 언어\n모델에게 문제를 해결하는 과정을 단계별로 설명하도록\n하고 있다.\n(cid:13273)예시(cid:13274) 주차장에 3대의 차가 있고 2대가 더 들어오면 총 몇\n대의 차가 있는지 계산하는 문제가 있다. 모델은 있던 차\n3대에 더해진 2대를 더해서 5대가 있다고 답한다. 그리고\n새로운 산술 문제를 풀이하라고 모델에게 요구한다.\n새로운문제: 재닛의 오리들은 하루에 알을 16개 낳는다.\n재닛은 매일 아침 3개의 알을 먹고, 매일 4개의 알을\n머핀을 굽는데 사용한다. 나머지 알은 하나에 2달러씩\n판매한다. 재닛은 매일 얼마를 벌까?\n(cid:13968)2단계(cid:13967) 여러가지경로샘플링: 재닛의 오리들이 하루에\n16개의 알을 낳는다를 가정으로, 새로운 문제에 대한 여러\n계산 경로를 탐색한다. 매일 재밋이 얼마를 버는지를\n맞추기 위한 계산이다.\n(cid:13968)3단계(cid:13967) 모델이 일관된 답변을 도출하기 위해 2단계\n샘플링을 통해 나온 결과를 종합하여 추론한다. 그리고\n가장 많이 생성된 답변인 결과를 내놓는다. (cid:13900)18불이다.\nWang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., ... & Zhou, D. (2022). Self-consistency improves chain of thought reasoning in language models.arXivpreprint arXiv:2203.11171.",
      "char_count": 1012,
      "word_count": 189,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 48,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nSelf-Consistency 성능\no 수학 문제 정답을 맞춘 확률이 높음\no 다수결 투표 방식의 정확도가 높음\no Greedy decode: 단일 경로를 따라 답을 생성\nMethod: 사용된모델과기법\no Weighted avg (cid:13273)unnormalized(cid:13274): 가중 평균을 사용하여 답을 도출\no CoT(cid:13247)prompting: Chain(cid:13247)of(cid:13247)Thought 프롬프팅을 사용한 성능\no Weighted sum (cid:13273)normalized(cid:13274): 정규화된 가중 합을 사용하여 답을 도출U\no Self(cid:13247)consistency: Self(cid:13247)Consistency 기법을 사용한 성능\no weighted sum (cid:13273)majority vote(cid:13274): 다수결 투표 방식",
      "char_count": 484,
      "word_count": 67,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 49,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nResearch Paper\nü 복잡한 추론 작업에서 비용 효율적\nü 다양한 추론 경로를 통한 높은 정확도\nFigure 2: Self-consistency (blue) significantly improves accuracy over CoT-prompting with greedy decoding (orange) across arithmetic and\ncommonsense reasoning tasks, over LaMDA-137B. Sampling a higher number of diverse reasoning paths consistently improves reasoning accuracy.\n§ Self(cid:13247)Consistency의 한계점\no 복잡한 추론 작업을 해결 할 때 비용이 많이 듦\no 복잡한 추론을 해결하려면, 상당한 양의 훈련 데이터 필요. 모델이 일관된 응답을 효과적으로 생성하기 위해\n다양한 추론 패턴을 학습해야 하기 때문\no 프롬프트가 명확하지 않거나 간결하지 않을 때, Self(cid:13247)Consistency의 기법 성능이 저하됨",
      "char_count": 572,
      "word_count": 96,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 50,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\n실습\n아래 텍스트는 소프트회사의 보안관련 이메일입니다.\n이메일 내용 중에서 비즈니스에 중요한 영향을 미치는 내용과 아닌 내용을\nSelf(cid:13247)Consistency Prompting 기법을 사용하여 구분해보세요.\n이메일 내용\n안녕하세요,\n귀사의 시스템에서 중요한 보안 취약점을 발견하게 되어 이와 관련된 사항을 공유하고자 합니다.\n이 취약점은 악용이 쉽지 않지만, 이를 통해 모든 사용자 데이터에 접근할 수 있는 가능성이\n있습니다. 이에 대한 증거로 개념 증명 파일을 첨부했으니 확인해 주시기 바랍니다.\n이 문제는 매우 심각하며, 조속한 시일 내에 해결해 주실 것을 요청드립니다.\n해당 취약점을 통해 발생할 수 있는 잠재적 위협을 방지하기 위해, 귀사의 보안 팀에서 신속하게\n대응해 주시기를 바랍니다. 추가적인 정보가 필요하거나, 제가 더 도울 수 있는 부분이 있다면\n언제든지 연락해 주시기 바랍니다.빠른 시일 내에 문제 해결을 부탁드리며, 이러한 문제를 미리\n발견하게 되어 다행이라고 생각합니다.\n귀사의 보안 강화를 위해 함께 협력할 수 있기를 기대합니다.\n감사합니다.",
      "char_count": 573,
      "word_count": 128,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 51,
      "text": "Chapter 3. 프롬프트 엔지니어링 기초. \n실습 Generated by gpt-3.5-turbo \nTemp: 0.3 \ngpt-3.5-turbo こ \nSYSTEM \nEnter system instructions \nUSER \n아래 이메일 내용을 읽고 비즈니스와 관련하여 중요한 내용과 중요하지 않은 내용을 \"IMPORTANT\" or \"NOT \nIMPORTANT\" 를 구분해줘. 그리고 아래처럼 대답해줘. \nResponse template: \n{Important} :{ } \n{Not Important} : { } \nLet's think step by step. \n##이메일 \n안녕하세요, 귀사의 시스템에서 중요한 보안 취약점을 발견하게 되어 이와 관련된 사항을 공유하고자 합니다. 이 취약점은 \n악용이 쉽지 않지만, 이를 통해 모든 사용자 데이터에 접근할 수 있는 가능성이 있습니다. 이에 대한 증거로 개념 증명 파일 \n을 첨부했으니 확인해 주시기 바랍니다. 이 문제는 매우 심각하며, 조속한 시일 내에 해결해 주실 것을 요청드립니다. 해당 \n취약점을 통해 발생할 수 있는 잠재적 위협을 방지하기 위해, 귀사의 보안 팀에서 신속하게 대응해 주시기를 바랍니다. 추가 \n적인 정보가 필요하거나, 제가 더 도울 수 있는 부분이 있다면 언제든지 연락해 주시기 바랍니다. 빠른 시일 내에 문제 해결 \n을 부탁드리며, 이러한 문제를 미리 발견하게 되어 다행이라고 생각합니다. 귀사의 보안 강화를 위해 함께 협력할 수 있기를 \n기대합니다. 감사합니다. \nFast campus",
      "char_count": 763,
      "word_count": 162,
      "needs_ocr": true,
      "ocr_status": "success"
    },
    {
      "page_num": 52,
      "text": "Chapter 3. 프롬프트 엔지니어링 기초. \n1번 ASSISTANT \n{Important} : { 보안 취약점 발견, 모든 사용자 데이터에 접근 가능성, 증거 첨부, 심각성 강조, 조속한 대응 요청, 보안 팀 대 \n응 요청, 잠재적 위협 방지, 협력 요청} \n{Not Important} : { 인사말, 도움 제안, 다행이라는 감사 표현 } \n2번 ASSISTANT \n{Important} : { 보안 취약점 발견, 모든 사용자 데이터에 접근 가능성, 증거 첨부, 문제 심각성 강조, 조속한 대응 요청, 보안 \n팀 대응 요청, 잠재적 위협 방지, 보안 강화 협력 요청} \n{Not Important} : { 이메일의 시작 및 인사말, 추가적인 정보 및 도움 제안, 다행이라는 감사 표현} \n3번 ASSISTANT \n{Important} : { 보안 취약점 발견, 모든 사용자 데이터에 접근 가능성, 증거 첨부, 심각한 문제, 조속한 대응 요청, 잠재적 위 \n협 방지, 보안 팀 대응 요청, 문제 해결 요청, 보안 강화 협력 요청 } \n{Not Important} : { 개념 증명 파일 첨부, 추가 정보 및 도움 제공 가능 여부, 미리 발견해서 다행이라는 감사 인사} \nFast campus",
      "char_count": 612,
      "word_count": 152,
      "needs_ocr": true,
      "ocr_status": "success"
    },
    {
      "page_num": 53,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\n학습 목표\nü01\n프롬프트 엔지니어링 기초 기법을 이해한다.\n02\n연구 논문을 통해 각 프롬프트 엔지니어링 기법의 핵심과 한계를 이해한다.\n03\n실습을 통해 각 프롬프트 엔지니어링 방법을 학습한다.",
      "char_count": 134,
      "word_count": 30,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    },
    {
      "page_num": 54,
      "text": "Chapter 3. 프롬프트엔지니어링기초.\nReferences\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language\nmodels are few-shot learners. Advances in Neural Information Processing Systems, 33, 1877-1 901.\nChristiano, P. F., Leike, J., Brown, T., Martic, M., Legg, S., & Amodei, D. (2017). Deep reinforcement learning from\nhuman preferences. Advances in Neural Information Processing Systems, 30.\nMann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., ... & Amodei, D. (2020). Language\nmodels are few-shot learners. arXiv preprint arXiv:2005.14165.\nWang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., ... & Zhou, D. (2022). Self-consistency improves chain\nof thought reasoning in language models. arXiv preprint arXiv:2203.11171.\nWork, W. M. I. C. L. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?.\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., ... & Zhou, D. (2022). Chain-of-thought prompting\nelicits reasoning in large language models. Advances in Neural Information Processing Systems, 35,\n24824-24837.",
      "char_count": 1121,
      "word_count": 167,
      "needs_ocr": false,
      "ocr_status": "not_needed"
    }
  ]
}
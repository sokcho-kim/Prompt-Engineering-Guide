# 7단계: 프롬프트 품질 관리 - 테스트 방법론

> 학습일: 2026-01-09
> 출처: Fastcampus Part 6

---

## 1. 프롬프트 테스트의 필요성

### 테스트의 어려움

| 문제 | 설명 |
|------|------|
| 프롬프트 = 텍스트 | 정량화 어려움 |
| 일관성/품질 안정성 | 같은 프롬프트도 결과가 다름 |
| 정답이 없음 | 프롬프트 ≠ 정답 |
| 빠른 발전 속도 | LLM 변화에 대응 필요 |

### 반복적 개발 프로세스

```
설계 → 테스트 → 분석 → 개선 → 설계 → ...
```

---

## 2. 프롬프트 테스트 9가지 규칙

| # | 규칙 | 예시 |
|---|------|------|
| 1 | 최소 **두 가지 버전** 작성 | v1, v2 |
| 2 | **기능 이름**으로 버전명 | `systemprompt_v1` |
| 3 | **세부 카테고리** 반영 | `FinancialAnalysis_Revenue_v1` |
| 4 | **목표와 기대 성능** 문서화 | 기대 결과 명세 |
| 5 | **작위적 문장 금지** | 실제 사용자 데이터 사용 |
| 6 | **테스트 데이터셋** 사용 | 다양한 케이스 커버 |
| 7 | **최소 10번 이상** 생성 | OpenAI Playground |
| 8 | **최소 3명** 관계자 참여 | 다양한 관점 |
| 9 | **다양한 모델**로 테스트 | GPT-4, Claude, Gemini |

---

## 3. 테스트 데이터셋 요건

### 필수 포함 데이터

```yaml
- 대표적/빈번한 실제 사용자 발화
- 다양하고 포괄적인 내용
- 예상치 못한 사항 (edge cases)
- 사용자 오류 패턴
- LLM 한계가 드러난 발화
```

### scrape-hub 적용

```yaml
NER 검증 테스트 데이터셋:
  - 정상 케이스: "HER2 양성 환자" → HER2 (유효)
  - 부분 문자열: "cancer 관련" → er (무효)
  - 동음이의어: "ER 양성" vs "emergency room"
  - 경계 케이스: "무증상" → 증상부재 vs 질병명
  - LLM 실패: 복잡한 의료 용어
```

---

## 4. 프롬프트 문서화 템플릿

```yaml
프롬프트 유형: Type C
제목: Question_Generator
설명: 사용자가 후속 질문으로 자주 물을 것 같은 질문 생성

기대 결과:
  - 사용자 질문과 관련된 3개 답변
  - 내용이 서로 겹치지 않음
  - 한국어 답변
  - 적절한 길이
  - 글자 깨짐/특수기호 없음
  - 멀티턴에서도 주제 유지

작업 과정 이슈:
  - 최대 토큰 수 초과 시 기능 중단
  - 이전 대화 기억 필요
  - 주제 전환 후 복귀 대응

기타 메모:
  - 기업 광고 활용 가능성
  - 개인 맞춤형 제작 가능
```

---

## 5. 테스트 방법론

### 5.1 정성적 분석

#### 1단계: 목적 확인

```
(1) 핵심 단어/구문 추출
    - 모델 응답 생성에 중요한 역할
    - 적절한 키워드 식별

(2) 문장 구성 분석
    - 단순한지 vs 복잡한지
    - 명령어인지 vs 질문인지
    - 정보 흐름이 논리적인지
```

#### 2단계: 구조 분석

```
프롬프트 구조 패턴:
  Type 1: 지시 → 템플릿 → 엔딩
  Type 2: 지시 → 엔딩 → 템플릿

변수 순서 테스트:
  {$지시} → {$엔딩} → {$답변 템플릿}
  {$지시} → {$답변 템플릿} → {$엔딩}
  ...
```

#### 3단계: 효율성 평가

```
(1) 프롬프트 길이
    - 불필요하게 긴지?
    - 더 간단하게 표현 가능한지?

(2) 컨텍스트 평가
    - 충분한지?
    - 과도한지?
```

### 5.2 프롬프트 테스트 루브릭

| 평가 항목 | 점수 | 기준 |
|----------|------|------|
| **정확성** | 1-5 | 주제와 맞게 생성하는가 |
| **일관성** | 1-5 | 내용 흐름과 전개 방식 일정한가 |
| **유용성** | 1-5 | 바로 사용 가능한가 |
| **문법/문체** | 1-5 | 자연스러운 언어인가 |
| **모델 대응** | 1-5 | 다양한 모델에서 작동하는가 |
| **총점** | /25 | |

#### 평가 예시

```yaml
프롬프트: 각 슬라이드 내용 작성 프롬프트 A
목적: 주제에 맞게 슬라이드 내용 완성

평가:
  정확성: 2  # 100% 맞지 않음
  일관성: 5  # 흐름 있고 전개 일정
  유용성: 2  # 추가 수정 필요
  문법/문체: 5  # 자연스러운 한국어
  모델 대응: 5  # GPT-4-turbo 품질 좋음

총점: 19/25

개선 사항:
  - 내용 정확성 보완
  - 유용한 내용 생성하도록 개선
  - 주제에 맞는 자세한 내용 생성
```

### 5.3 정량적 분석

#### N번 생성 테스트

```python
# N > 100 권장
for i in range(100):
    response = llm.generate(prompt)
    results.append(response)

# 응답 패턴 분석
pattern_analysis(results)
```

#### 응답 패턴 분석

```yaml
질문: "개발자로 살아남으려면?"
N = 20회 테스트

패턴 분포:
  - "기술 학습" 관련: 15회 (75%)
  - "경력 관리" 관련: 12회 (60%)
  - "커뮤니티" 관련: 8회 (40%)
  - 기타: 5회 (25%)
```

#### 모델별 비교

| 모델 | 정확성 | 일관성 | 응답 시간 |
|------|--------|--------|----------|
| GPT-4o | 4.5 | 4.8 | 2.3s |
| GPT-4o-mini | 4.2 | 4.5 | 1.1s |
| Claude-3.5 | 4.6 | 4.7 | 1.8s |
| Gemini Pro | 4.0 | 4.3 | 1.5s |

---

## 6. 테스트 업무 절차

```
1. 테스트 기준 마련
   ↓
2. 테스트 결과 정리
   ↓
3. 프롬프트 품질 분석
   ↓
4. 프롬프트 언어 분석
   ↓
5. 최종 프롬프트 선별
   ↓
6. 사용자 피드백/이슈 관리
   ↓
7. 지속적 개선
```

---

## 7. scrape-hub 적용

### NER 검증 프롬프트 테스트

```yaml
프롬프트: ner_validation_v3
테스트 데이터셋: ner_test_v2.jsonl

루브릭 평가:
  정확성: 4  # 대부분 정확
  일관성: 4  # CoT로 일관된 추론
  유용성: 5  # 바로 적용 가능
  문법/문체: 5  # 명확한 출력
  모델 대응: 3  # 일부 모델 성능 차이

총점: 21/25

개선 사항:
  - 모델별 프롬프트 최적화
  - edge case 추가 커버
```

### 테스트 데이터셋 구성

```yaml
ner_test_v2.jsonl:
  - 정상 케이스: 50%
  - 부분 문자열 오류: 20%
  - 동음이의어: 15%
  - 맥락 무관: 10%
  - LLM 한계: 5%
```

---

## 8. 테스트 도구

| 도구 | 용도 |
|------|------|
| **OpenAI Playground** | 빠른 프로토타이핑 |
| **The Prompt Testbed** | 체계적 테스트 |
| **LangSmith** | 추적/평가 |
| **자체 스크립트** | 대량 테스트 자동화 |

---

## 학습 완료 체크

- [x] 테스트 9가지 규칙
- [x] 테스트 데이터셋 요건
- [x] 정성적 분석 (목적, 구조, 효율성)
- [x] 테스트 루브릭
- [x] 정량적 분석 (N번, 패턴, 모델별)
- [ ] 실제 테스트 실습

---

## 참고 자료

- Fastcampus Part 6: 프롬프트 품질 관리 - 테스트 방법론
- The Prompt Testbed: https://the-prompt-playground.vercel.app/
- Microsoft: Iterative process for prompt development
